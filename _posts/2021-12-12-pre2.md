---
layout: post
title:  "[project3-3] preprocessing test2 "

---

# 다양한 전처리 시도
이후에서는 인식률을 높이기 위한 아래의 다양한 방법을 연습해보겠습니다. 
  - Denoising
    - Gaussian filtering
    - Sharpening
    - Adaptive thresholding
  - Edge detection
    - Sobel
    - Canny


### gaussian filtering & sharpening
```python
'''
1. Gaussian Filter
2. Sharpening
'''
blur = cv2.GaussianBlur(img, (1, 1), 0)  # kernel size 크게 잡지 않도록 주의
sharp = np.clip(2.0*img - blur, 0, 255).astype(np.uint8)
ret1, th1 = cv2.threshold(blur, 0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
ret2, th2 = cv2.threshold(sharp, 0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

images=[th1, th2]
titles=["blur > otsu", "blur > sharpening > otsu"]
plt.figure(figsize=(30,15))
for i in range(2):
  plt.subplot(1,2,i+1), plt.imshow(images[i], "gray")
  plt.title(titles[i]), plt.xticks([]), plt.yticks([])

```
![image](https://user-images.githubusercontent.com/86705085/145716954-2cddd263-5b8d-45a2-bd50-65d61cbb3df3.png)


```python
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray_img, (1, 1), 0)  # kernel size 크게 잡지 않도록 주의
sharp = np.clip(2.0*gray_img - blur, 0, 255).astype(np.uint8)
ret1, th1 = cv2.threshold(blur, 0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
ret2, th2 = cv2.threshold(sharp, 0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

########################### text detection algorithm adaption ######################################
config = r'--oem 3 --psm 6 outputbase digits' # 숫자만 
boxes_num = pytesseract.pytesseract.image_to_data(th2, lang='kor+eng', config=config)  # 숫자만

for idx, b in enumerate(boxes_num.splitlines()):
    '''
    숫자를 가리는 알고리즘 
    '''
    if idx != 0:  # head를 제외하고 split
        b = b.split()
        if len(b) == 12:  # 객체가 있는것만 뽑아서
            if ('.' not in b[11]) and (len(b[11])>=13):
                x,y,w,h = int(b[6]),int(b[7]),int(b[8]),int(b[9])
                cv2.rectangle(img, (x,y),(x+w,y+h),(255,0,0), -1)   # 좌상단, 우하단
                cv2.putText(img, b[11], (x,y+25), cv2.FONT_HERSHEY_COMPLEX, fontScale=0.5, color=(0,0,255), thickness=1)

cv2_imshow(img)
```
![image](https://user-images.githubusercontent.com/86705085/145716450-ce507153-72c1-4023-8760-479c5008b071.png)


##### sharpening 별 효과 없었음 확인
  - 눈으로는 txt와 배경의 차이가 강해져서 더 잘잡을 것이라 생각함
  - 그러나 결과는 별 차이 없음 (거의 동일)
  - 눈으로 확인할때와 컴퓨터가 인식할때는 확실히 차이가 있나보다...


# Edge detection 적용
  - edge란 영상에서 픽셀값이 급격하게 변하는 부분
  - 일반적으로 배경과 객체, 또는 객체와 객체의 경계
  - 영상을 (x,y)함수로 간주했을 때, foc값이 크게 나타나는 부분을 검출

### Sobel
```python
dx = cv2.Sobel(th1, -1, 1,0, delta=0)  # x방향
dy = cv2.Sobel(th1, -1, 0,1, delta=255)  # y방향
```
![image](https://user-images.githubusercontent.com/86705085/145716492-0f4ca150-0d62-4ba3-ab4a-c4216b5981fe.png)
![image](https://user-images.githubusercontent.com/86705085/145716495-1a1e5310-fd8e-47a3-94d6-26c40129f0be.png)


```python
dx = cv2.Sobel(th1, cv2.CV_32F, 1,0)  # x방향. delta default = 0
dy = cv2.Sobel(th1, cv2.CV_32F, 0,1)  # y방향
# 방향상관없이 gradiant 크기 보기
mag = cv2.magnitude(dx, dy)
mag = np.clip(mag, 0, 255).astype(np.uint8)
cv2_imshow(mag)
```
![image](https://user-images.githubusercontent.com/86705085/145716519-9c28d157-7147-415a-a70c-6c3fc08db977.png)


### Canny
(Canny detection 순서)
  - 가우시안 필터링 > 그래디언트 계산 > NMS >이중 임계값을 이용한 히스테리시스 에지 트래킹

```python
canny = cv2.Canny(th1, 50,150)
cv2_imshow(canny)
```
![image](https://user-images.githubusercontent.com/86705085/145716537-8809df4d-8b4d-4988-a7db-b6142f5f7bd4.png)


### Morphology
```python
mp1 = cv2.dilate(th1, None)
se= cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))
mp2 = cv2.erode(th1, se)
cv2_imshow(mp1)
cv2_imshow(mp2)
```
![image](https://user-images.githubusercontent.com/86705085/145716689-76d338d3-0ca9-4934-9a43-358dfc46fc6d.png)
![image](https://user-images.githubusercontent.com/86705085/145716691-88ae12ae-3d7d-40ae-91e6-fb156f94e52f.png)


```python
se= cv2.getStructuringElement(cv2.MORPH_RECT, (1,2))
mp2 = cv2.erode(th1, se)
cv2_imshow(mp2)
```
![image](https://user-images.githubusercontent.com/86705085/145716714-a8c7615d-0398-448c-9cd6-6bf481ebffe7.png)




결국 최종후보로 아래의 이미지들이 뽑혔다.
성능이 가장 좋은 것을 테스트해볼 것이다. 시간이 나기를..

```python
gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
blur = cv2.GaussianBlur(gray_img, (1, 1), 0)  # kernel size 크게 잡지 않도록 주의
sharp = np.clip(2.0*gray_img - blur, 0, 255).astype(np.uint8)
ret1, th1 = cv2.threshold(blur, 0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
ret2, th2 = cv2.threshold(sharp, 0,255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
dx = cv2.Sobel(th1, cv2.CV_32F, 1,0)  # x방향. delta default = 0
dy = cv2.Sobel(th1, cv2.CV_32F, 0,1)  # y방향
mag = cv2.magnitude(dx, dy) # 방향상관없이
mag = np.clip(mag, 0, 255).astype(np.uint8)
canny = cv2.Canny(th1, 50, 150)
mp1 = cv2.dilate(th2, None)
se= cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))
mp2 = cv2.erode(th1, se)
```
