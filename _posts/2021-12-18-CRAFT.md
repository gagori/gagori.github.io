---
layout: post
title:  "[project3-9] Text Detection by CRAFT & Tesseract OCR"

---

# Text Detection by CRAFT

이전 포스팅에서  한글데이터를 다운받아 한글 Recognition 성능을 높이고자 시도하였다. 그러나 프로젝트 마감기한이 다가오고 4기가가 넘는 데이터양과 학습시간을 고려하니 직접 fine tuning을 시키는 방법보다는 pre train모델을 몇개 가져와서 성능을 비교해보는 방법을 택했다.

결론적으로 **Text Detection 모델을 따로 가져와서 검출된 roi를 tesseract로 넘기고 OCR을 진행하는 방식**을 택하였다.

위와같은 방법을 택한 이유는 다음과 같다.
 Tesseract를 기본 OCR모델로 사용한다. 이때 text가 아닌 영역역을 검출하거나 혹은 띄어진 단어인데 같은 단어로 인식하는 문제가 발생했다. 

![image](https://user-images.githubusercontent.com/86705085/147201951-872a1b8c-a82b-4fb0-863f-2196d32ea315.png)


따라서 이를 해결하고자 Text Detection모델을 따로 가져온 것이다.
**그렇다면 왜 CRAFT인가?**
이유를 알기위해 CRAFT가 도출하는 결과값을 살펴본다.


**CRAFT는 두가지 Score를 리턴해준다.**
1. Region Score : 해당 픽셀이 text의 중심이 될 확률
2. Affinity Score : 해당 픽셀이 text와 text사이의 중심이 될 확률

![image](https://user-images.githubusercontent.com/86705085/147202028-9d04d802-bbe2-4b36-8bba-f0002d4a8dd0.png)


text detection 이후 roi 값을 주기 때문에 해당 영역에만 tesseract를 적용하여 ocr을 수행할 수 있어서 앞선 문제점이 해결되었다.
또한  Affinity Score를 가지고 우리가 직면한 문제를 해결할 수 있었다. 같은 단어로 인식하던 글자를 threshold를 높혀가며 다른 단어로 인식시킬 수 있었다.



![image](https://user-images.githubusercontent.com/86705085/147202317-1e0c4db6-7ae8-4536-999f-af702486a970.png)


따라서 이후에서는 craft를 detection 모델로 가져와서 roi를 활용할 것이다.
또한 이를 tesseract로 받아 최종 OCR을 진행한다.


![image](https://user-images.githubusercontent.com/86705085/147202619-d63c2df6-e7ad-4785-b93f-41a1f9e1b884.png)





사용한 코드는 다음과 같다.

1. CRAFT 모델 불러와서 ROI 리턴받기
```python
import cv2
from craft_text_detector import (read_image,load_craftnet_model,load_refinenet_model,get_prediction,)


def  get_roi(image):
	# load models
	refine_net = load_refinenet_model(cuda=False)
	craft_net = load_craftnet_model(cuda=False)

	# perform prediction
	prediction_result = get_prediction(image=image,
											craft_net=craft_net,
											refine_net=refine_net,
											text_threshold=0.9,
											link_threshold=0.5, # 클수록 잘게 자름
											low_text=0.6, # 작을수록 bboxes 오차범위 키움
											long_size=1280)
	# get roi
	roi = []
	for i in  range(len(prediction_result["boxes"])):
		left, top = map(int, prediction_result["boxes"][i][0])
		right, bottom = map(int, prediction_result["boxes"][i][2])
		# print(left, top, right, bottom)
		roi.append([left,top,right,bottom])
	# print(roi)

	return roi
```

2. ROI를 가지고 TESSERACT로 OCR 진행
```python
import  cv2
import  craft
import  pytesseract
import  re

pytesseract.pytesseract.tesseract_cmd ='C:/Program Files/Tesseract-OCR/tesseract.exe'  

# text 정제처리 : 특수문자 삭제
def  clean_text(read_data):
	text = re.sub('[0123456789]', '', read_data)
	return  text

def  craft_tesseract(dst, th1):
	roi = craft.get_roi(th1)
	myData=[]
	numData=[]
	for  x,r  in  enumerate(roi):
		left, top = r[0]-10,r[1]-5
		right, bottom = r[2]+5,r[3]+5
		imgCrop = th1[top:bottom , left:right] #h,w
		# cv2.imshow(str(x), imgCrop)

		config = r'--oem 2 --psm 6 -c tessedit_char_whitelist=0123456789-.'
		number_info = pytesseract.image_to_string(imgCrop, lang='kor',config=config)
		numData.append(number_info)
		if ('-'  in  number_info) and ('.'  not  in  number_info) and  len(number_info) > 8:
			cv2.rectangle(dst, (left,top), (right,bottom), (0,0,0), -1)



	myData = "".join(numData)

	return  myData, dst
```





참고사이트
 - https://medium.com/@msmapark2/character-region-awareness-for-text-detection-craft-paper-%EB%B6%84%EC%84%9D-da987b32609c
 - https://pypi.org/project/craft-text-detector/




