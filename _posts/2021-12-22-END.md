---
layout: post
title:  "[project3-10] 프로젝트 마무리 "

---

# 프로젝트 마무리

우선 우리가 진행했던 과정을 복습하면서 요약해보자. 간단히 아래의 flow chart를 살펴보자.


![image](https://user-images.githubusercontent.com/86705085/147212441-53525a9c-8b3f-41a5-9db8-55eb2968675d.png)


1. 인풋 이미지로 신분증 사진이 들어간다.
2. 기본적인 전처리가 진행된다.
	- Gaussian blur와 OTSU binarization
3.  비뚤어진 이미지라면 skew correction을 통해 이미지를 바로잡는다.
	- HoughLines_P와 getRotationMatrix2D
	
4.  OCR과 Face Deteciton이 동시에 진행된다. 이때 사용하는 모델은 아래와 같다.

![image](https://user-images.githubusercontent.com/86705085/147213014-0538cfbe-a585-4a96-b434-2c893cd8ddab.png)

5.  마지막으로 이미지가 마스킹되면서 output 도출된다.

![image](https://user-images.githubusercontent.com/86705085/147213239-03b9d9ec-915e-4724-a10a-f7064134333c.png)


6.  이후에는 데이터베이스(mongo DB)에 정보가 저장되고,  웹으로 확인할 수 있다.




# ______________________________________________________________________________


이번 프로젝트를 진행하면서 한글 OCR은 아직 갈길이 멀다는 것을 경험하였다.
이후에는 앞서 계획했던 것 처럼 
1. AI HUB에서 구한 한글데이터를 사용하여 
2. NAVER Clova ai에서 제공하는 Text recognition pre -trained 모델인 TPS-ResNet을  가져오고 
3. 직접 Fine tuning을 진행하여 tesseract보다 나은 성능의 OCR모델을 구현하고 싶다.







